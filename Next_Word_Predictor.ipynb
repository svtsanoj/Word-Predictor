{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word-predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-7up7sQ-Thv",
        "colab_type": "text"
      },
      "source": [
        "# **Next Word Predictor**\n",
        "\n",
        "## I have implemented a 'next word predictor' using 2 different methods.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.    **Using GloVe pretrained Embedding Layer**\n",
        "  - I initially tried an embedding layer which was trained from scratch along with the model, but i did not get a good result. So I have chosen a pretrained embedding layer because of the low resource available and the fact that the corpus has more High Frequency words and long sentences.\n",
        "So it would be better to start with pretrained weights as it would be easier to map High frequency words.\n",
        "\n",
        "\n",
        "\n",
        "2.   **Tried adding POS_Tag as a feature to the input and feeding directly to LSTM**\n",
        "        - I had not  come across any implementations of using POS( Part of Speech) of words as an additional feature, so i have given it a try. It does not work as espected though.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVdyjpHCUtNi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Implementation 1**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ByUgo6mzbk",
        "colab_type": "code",
        "outputId": "2c9b5a3a-d673-4794-c86e-b60d15b3e708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "!git clone https://github.com/svtsanoj/Word-Predictor.git\n",
        "\n",
        "!7z e \"/content/Word-Predictor/Word-Predictor.7z\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Word-Predictor' already exists and is not an empty directory.\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/Word-Predictor/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 71604256 bytes (69 MiB)\n",
            "\n",
            "Extracting archive: /content/Word-Predictor/Word-Predictor.7z\n",
            "--\n",
            "Path = /content/Word-Predictor/Word-Predictor.7z\n",
            "Type = 7z\n",
            "Physical Size = 71604256\n",
            "Headers Size = 273\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  6% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 1 - glove.6B.50d.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 - word_model_8_gram.h5\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 - word_model_8_gram.h5\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 - word_model_8_gram.h5\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 3 - word_with_pos.h5\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       187529191\n",
            "Compressed: 71604256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRZh00-hNrlo",
        "colab_type": "code",
        "outputId": "0761a1f4-732a-4011-db63-2eec3cb3f370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "import keras\n",
        "from numpy import array, asarray\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras import models\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ88HDCwTlSv",
        "colab_type": "text"
      },
      "source": [
        "##Validation Text\n",
        "This is a random validation text that i wrote making sure most words are in vocabulary of the corpus.\n",
        "\n",
        "Validation Text is added to the corpus and later split as training and testing data to ease preprocessing efforts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQju9IIPWd1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_text= \"\"\"\n",
        "the man pushed the woman away and asked the surgeon whether the man is dead. \n",
        "How can someone do this to him? \n",
        "he was a good man. \n",
        "I wanted him to die, said the woman. \n",
        "the man was agitated. \n",
        "He turned around as there was a hand on his shoulder.\n",
        "A tall man stood motionless. \n",
        "I should not go out at this hour of the day. \n",
        "It was cold outside and I was wet. \n",
        "I looked up to see if the stars were out. \n",
        "I do not know what to say. \n",
        "This information is useless. \n",
        "this produced a good impression on my mother. \n",
        "I will never leave you alone or out of sight. \n",
        "you must be with me.\n",
        "where was that. \n",
        "where is it\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCPQmtDHFW89",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Data\n",
        "**Split Into Sentences** : If the words from the corpus are provided as a continous sequence to train on, It loses its syntactic structure when the end of a certain sentences is combined with the beginning of another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaBMw3jGNzjx",
        "colab_type": "code",
        "outputId": "f12e97f2-3d9a-4b30-fe1b-4ecaf6c515ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "path=\"/content/corpus.txt\"\n",
        "with open(path) as f:\n",
        "    text = f.read().lower().replace(\"\\n\",\" \") # there are no \\t so we just replace \\n\n",
        "    \n",
        "text = re.split(\"[.?!;]+\", text)              \n",
        "val_text = re.split(\"[.?!;]+\", val_text) \n",
        "val_len = len(val_text)\n",
        "i = 0\n",
        "dummy = []\n",
        "for sentence in text:\n",
        "    text[i] = re.sub(\"\\s+\", \" \", (re.sub(\"[^a-z ]+\", \" \", sentence))) # replace everything but lower case letters and spaces with \" \" and remove extra spaces.\n",
        "    k = text[i].split()\n",
        "    if(len(k)>1):\n",
        "      dummy.append(k)\n",
        "    i += 1\n",
        "text = dummy\n",
        "\n",
        "print(\"Total Sentences in Training Data: \" ,len(text))\n",
        "print(\"Total Sentences in Validation Data: \", val_len)\n",
        "text[1] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sentences in Training Data:  256\n",
            "Total Sentences in Validation Data:  17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'night', 'was', 'wet', 'and', 'cold']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZN3_XJN8YH",
        "colab_type": "code",
        "outputId": "9b9a09cb-fd01-494b-80fe-986c6d005cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = 0\n",
        "for i in range(len(text)):\n",
        "  l = len(text[i])\n",
        "  # print(l)\n",
        "  s += l\n",
        "avg=s/len(text)\n",
        "print(\"avg sentence length: %f\"%(avg))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg sentence length: 17.925781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3WJTDrYIRDJ",
        "colab_type": "text"
      },
      "source": [
        "## Keras tokenizer\n",
        "### Alternatively, mapped words to tokens\n",
        "  ```\n",
        "word_to_ix = { word:i for i,word in enumerate(wh_text) } #From Andrej Karpathy's Char RNN Implementation\n",
        "seqlength = 5\n",
        "X,y=[],[]\n",
        "#wrote this for having all words as a continous sequence and splitting Input sequence with length = 5\n",
        "for i, word in enumerate(wh_text[:-seqlength]): \n",
        "  X.append(list(word_to_ix[wrd] for wrd in wh_text[i:i+seqlength]))\n",
        "  y.append(word_to_ix[wh_text[i+seqlength]])\n",
        "print(X[:5])\n",
        "print(y[:5])\n",
        "  ```\n",
        " ### But keras tokenizes based on the frequency of words. Which is an useful feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NMb7GLu88_6",
        "colab_type": "code",
        "outputId": "1b9d91d5-8651-4bcb-c640-d335b7775479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "data = tokenizer.texts_to_sequences(text)\n",
        "vocab_size = len(tokenizer.word_counts) + 1\n",
        "print(\"vocab_size\", vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size 1335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O986-_cvLSKe",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation Data\n",
        "\n",
        "As we have to work with limited data and that too restricting ourselves from picking word combinations only from each sentences, I have implemented a **n-gram** split of sentences.\n",
        "\n",
        "###Eg: a man was standing outside the house. \n",
        "So let's split these words into a sequences of Maximum length of 5 and Minimum of 1 for input (X) and , 1 word for output (y).\n",
        "\n",
        "\n",
        "**len = 5**\n",
        "\n",
        "**X:**[\"a\", \"man\", \"was\", \"standing\", \"outside\"],  **y:**[the]\n",
        "\n",
        "**X:**[\"man\", \"was\", \"standing\", \"outside\", \"the\"],  **y:**[house]\n",
        "\n",
        "**len =2**\n",
        "\n",
        "**X:**[0, 0,  0, \"a\", \"man\"],     **y:**[\"was\"]\n",
        "\n",
        "**X:**[0, 0, 0, \"man\", \"was\"],     **y:**[\"standing\"]\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUL5-Gbe89HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqlength = 8\n",
        "X, y, X_val, y_val = [], [], [], []\n",
        "for i in range(1, seqlength+1):  #1-5 is the different sequence length of the input data\n",
        "  iter=0\n",
        "  for j in range(len(data)):\n",
        "    for k in range(len(data[iter])-i):\n",
        "      if(j<len(data)-val_len):\n",
        "        X.append(data[iter][k : k+i])\n",
        "        X[-1] = [0]*(seqlength-i) + X[-1] #pre-padding\n",
        "        #print(\"i j k data[iter][k:k+i] X\", i,j,k,data[iter][k:k+i], X)\n",
        "        y.append( data[iter][k+i] )\n",
        "      else:\n",
        "        X_val.append(data[iter][k : k+i])\n",
        "        X_val[-1] = [0]*(seqlength-i) + X_val[-1] #pre-padding\n",
        "        #print(\"i j k data[iter][k:k+i] X\", i,j,k,data[iter][k:k+i], X)\n",
        "        y_val.append( data[iter][k+i] )\n",
        "    iter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2aFJzI1Sd1d",
        "colab_type": "text"
      },
      "source": [
        "## Convert to Arrays\n",
        " X and y are converted into array data type from being lists. \n",
        " \n",
        " Here y is made into one shot encoded array using the keras to_cateorical() function.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp53z9YaSaWB",
        "colab_type": "code",
        "outputId": "14e260d3-d19a-4397-ec0a-56d4e10a5e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X = np.array(X, dtype='int32')\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "X_val = np.array(X_val, dtype='int32')\n",
        "y_val = to_categorical(y_val, num_classes=vocab_size)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27644, 8)\n",
            "(27644, 1335)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KvZ5qRqTAfx",
        "colab_type": "text"
      },
      "source": [
        "## GloVe Embedding Layer\n",
        "Have to download the 50 Dimensional GloVe Embeddings which is arounnd 160MB. It represents 400000 words as 50D vectors.\n",
        "\n",
        "[Reference for loading and using Pretrained Glove embedding](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRdQkU7U_ah6",
        "colab_type": "code",
        "outputId": "e3ab5a93-9ff6-4a00-8a05-38681ba3e80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Used From GloVe REFERENCE\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.50d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:])\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH1v8tS189R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used From GloVe REFERENCE\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaXFft0LSbpu",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "the pretrained embedding values are loaded into the embedding layer. We can choose to either update these weights or not using trainable = True or False\n",
        "\n",
        "Itereated over different parameters:\n",
        "- LSTM layer with 50 Units each\n",
        "- Dense layer neurons between 100 to 400\n",
        "- Batch Sizes - None, 128, 256\n",
        "\n",
        "- **Sequence Length** : 3 , 5, 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjapE8uz89Z9",
        "colab_type": "code",
        "outputId": "f1d16d8c-3cdb-4fdd-babe-d140f08bc76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=seqlength, trainable=True))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(400,activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, batch_size=256, validation_data=(X_val, y_val), verbose=1, shuffle='True')\n",
        "\n",
        "model.save(\"word_model_8_gram.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 8, 50)             66800     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 8, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 400)               40400     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1336)              535736    \n",
            "=================================================================\n",
            "Total params: 783,736\n",
            "Trainable params: 783,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 27644 samples, validate on 450 samples\n",
            "Epoch 1/100\n",
            "27644/27644 [==============================] - 5s 163us/step - loss: 6.2021 - accuracy: 0.0695 - val_loss: 5.8564 - val_accuracy: 0.0911\n",
            "Epoch 2/100\n",
            "27644/27644 [==============================] - 4s 150us/step - loss: 5.8735 - accuracy: 0.0729 - val_loss: 5.6522 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 5.4246 - accuracy: 0.0966 - val_loss: 5.4341 - val_accuracy: 0.1222\n",
            "Epoch 4/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 4.7994 - accuracy: 0.1219 - val_loss: 5.6140 - val_accuracy: 0.0978\n",
            "Epoch 5/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 4.3176 - accuracy: 0.1378 - val_loss: 6.0479 - val_accuracy: 0.1089\n",
            "Epoch 6/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 3.8836 - accuracy: 0.1689 - val_loss: 6.3224 - val_accuracy: 0.1111\n",
            "Epoch 7/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 3.4752 - accuracy: 0.2156 - val_loss: 6.7641 - val_accuracy: 0.0911\n",
            "Epoch 8/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 3.0965 - accuracy: 0.2759 - val_loss: 7.1644 - val_accuracy: 0.1400\n",
            "Epoch 9/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 2.7587 - accuracy: 0.3433 - val_loss: 7.7359 - val_accuracy: 0.1422\n",
            "Epoch 10/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 2.4598 - accuracy: 0.4086 - val_loss: 8.2155 - val_accuracy: 0.1222\n",
            "Epoch 11/100\n",
            "27644/27644 [==============================] - 4s 145us/step - loss: 2.2137 - accuracy: 0.4643 - val_loss: 8.7325 - val_accuracy: 0.1244\n",
            "Epoch 12/100\n",
            "27644/27644 [==============================] - 4s 145us/step - loss: 1.9824 - accuracy: 0.5190 - val_loss: 9.0961 - val_accuracy: 0.1533\n",
            "Epoch 13/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 1.7778 - accuracy: 0.5714 - val_loss: 9.5267 - val_accuracy: 0.1267\n",
            "Epoch 14/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 1.6023 - accuracy: 0.6168 - val_loss: 9.8245 - val_accuracy: 0.1467\n",
            "Epoch 15/100\n",
            "27644/27644 [==============================] - 4s 149us/step - loss: 1.4459 - accuracy: 0.6571 - val_loss: 10.1953 - val_accuracy: 0.1444\n",
            "Epoch 16/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 1.3158 - accuracy: 0.6905 - val_loss: 10.5789 - val_accuracy: 0.1178\n",
            "Epoch 17/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 1.1977 - accuracy: 0.7232 - val_loss: 10.9884 - val_accuracy: 0.1267\n",
            "Epoch 18/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 1.1004 - accuracy: 0.7491 - val_loss: 11.4071 - val_accuracy: 0.1333\n",
            "Epoch 19/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 1.0165 - accuracy: 0.7693 - val_loss: 11.6087 - val_accuracy: 0.1267\n",
            "Epoch 20/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 0.9488 - accuracy: 0.7843 - val_loss: 12.1978 - val_accuracy: 0.1244\n",
            "Epoch 21/100\n",
            "27644/27644 [==============================] - 4s 143us/step - loss: 0.8891 - accuracy: 0.7977 - val_loss: 12.2093 - val_accuracy: 0.1089\n",
            "Epoch 22/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 0.8363 - accuracy: 0.8081 - val_loss: 12.5837 - val_accuracy: 0.1356\n",
            "Epoch 23/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.7977 - accuracy: 0.8168 - val_loss: 12.7237 - val_accuracy: 0.1089\n",
            "Epoch 24/100\n",
            "27644/27644 [==============================] - 4s 155us/step - loss: 0.7601 - accuracy: 0.8258 - val_loss: 12.8494 - val_accuracy: 0.1422\n",
            "Epoch 25/100\n",
            "27644/27644 [==============================] - 4s 158us/step - loss: 0.7250 - accuracy: 0.8341 - val_loss: 13.2036 - val_accuracy: 0.1111\n",
            "Epoch 26/100\n",
            "27644/27644 [==============================] - 4s 152us/step - loss: 0.7032 - accuracy: 0.8355 - val_loss: 13.0798 - val_accuracy: 0.1489\n",
            "Epoch 27/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 0.6813 - accuracy: 0.8410 - val_loss: 13.5283 - val_accuracy: 0.1444\n",
            "Epoch 28/100\n",
            "27644/27644 [==============================] - 4s 150us/step - loss: 0.6569 - accuracy: 0.8433 - val_loss: 13.8157 - val_accuracy: 0.1467\n",
            "Epoch 29/100\n",
            "27644/27644 [==============================] - 4s 143us/step - loss: 0.6401 - accuracy: 0.8466 - val_loss: 14.0317 - val_accuracy: 0.1511\n",
            "Epoch 30/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.6278 - accuracy: 0.8471 - val_loss: 14.1589 - val_accuracy: 0.1356\n",
            "Epoch 31/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.6090 - accuracy: 0.8530 - val_loss: 14.3410 - val_accuracy: 0.1200\n",
            "Epoch 32/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.5988 - accuracy: 0.8539 - val_loss: 14.4080 - val_accuracy: 0.1333\n",
            "Epoch 33/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 0.5912 - accuracy: 0.8545 - val_loss: 14.3905 - val_accuracy: 0.1511\n",
            "Epoch 34/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 0.5775 - accuracy: 0.8573 - val_loss: 14.5686 - val_accuracy: 0.1422\n",
            "Epoch 35/100\n",
            "27644/27644 [==============================] - 4s 151us/step - loss: 0.5724 - accuracy: 0.8577 - val_loss: 14.4979 - val_accuracy: 0.1178\n",
            "Epoch 36/100\n",
            "27644/27644 [==============================] - 4s 146us/step - loss: 0.5587 - accuracy: 0.8590 - val_loss: 15.1007 - val_accuracy: 0.1400\n",
            "Epoch 37/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.5526 - accuracy: 0.8597 - val_loss: 15.1802 - val_accuracy: 0.1267\n",
            "Epoch 38/100\n",
            "27644/27644 [==============================] - 4s 150us/step - loss: 0.5510 - accuracy: 0.8587 - val_loss: 15.0288 - val_accuracy: 0.1511\n",
            "Epoch 39/100\n",
            "27644/27644 [==============================] - 4s 154us/step - loss: 0.5412 - accuracy: 0.8600 - val_loss: 15.2482 - val_accuracy: 0.1578\n",
            "Epoch 40/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 0.5402 - accuracy: 0.8605 - val_loss: 15.1657 - val_accuracy: 0.1511\n",
            "Epoch 41/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 0.5310 - accuracy: 0.8616 - val_loss: 15.5524 - val_accuracy: 0.1489\n",
            "Epoch 42/100\n",
            "27644/27644 [==============================] - 4s 150us/step - loss: 0.5268 - accuracy: 0.8630 - val_loss: 15.6705 - val_accuracy: 0.1333\n",
            "Epoch 43/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 0.5233 - accuracy: 0.8626 - val_loss: 15.9978 - val_accuracy: 0.1333\n",
            "Epoch 44/100\n",
            "27644/27644 [==============================] - 4s 137us/step - loss: 0.5211 - accuracy: 0.8629 - val_loss: 16.0014 - val_accuracy: 0.1378\n",
            "Epoch 45/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.5153 - accuracy: 0.8630 - val_loss: 15.9222 - val_accuracy: 0.1378\n",
            "Epoch 46/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 0.5150 - accuracy: 0.8633 - val_loss: 15.9995 - val_accuracy: 0.1467\n",
            "Epoch 47/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 0.5104 - accuracy: 0.8636 - val_loss: 15.9441 - val_accuracy: 0.1556\n",
            "Epoch 48/100\n",
            "27644/27644 [==============================] - 4s 140us/step - loss: 0.5085 - accuracy: 0.8632 - val_loss: 16.1005 - val_accuracy: 0.1333\n",
            "Epoch 49/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.5035 - accuracy: 0.8637 - val_loss: 16.0661 - val_accuracy: 0.1267\n",
            "Epoch 50/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.5017 - accuracy: 0.8633 - val_loss: 16.3960 - val_accuracy: 0.1333\n",
            "Epoch 51/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 0.4979 - accuracy: 0.8642 - val_loss: 16.2719 - val_accuracy: 0.1600\n",
            "Epoch 52/100\n",
            "27644/27644 [==============================] - 4s 145us/step - loss: 0.4933 - accuracy: 0.8652 - val_loss: 16.2315 - val_accuracy: 0.1289\n",
            "Epoch 53/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 0.4965 - accuracy: 0.8647 - val_loss: 16.3713 - val_accuracy: 0.1578\n",
            "Epoch 54/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.4941 - accuracy: 0.8653 - val_loss: 16.3564 - val_accuracy: 0.1444\n",
            "Epoch 55/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 0.4897 - accuracy: 0.8650 - val_loss: 16.3586 - val_accuracy: 0.1356\n",
            "Epoch 56/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.4879 - accuracy: 0.8651 - val_loss: 16.5804 - val_accuracy: 0.1444\n",
            "Epoch 57/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 0.4841 - accuracy: 0.8658 - val_loss: 16.5049 - val_accuracy: 0.1467\n",
            "Epoch 58/100\n",
            "27644/27644 [==============================] - 4s 152us/step - loss: 0.4828 - accuracy: 0.8653 - val_loss: 16.6399 - val_accuracy: 0.1422\n",
            "Epoch 59/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.4825 - accuracy: 0.8653 - val_loss: 16.8200 - val_accuracy: 0.1444\n",
            "Epoch 60/100\n",
            "27644/27644 [==============================] - 4s 133us/step - loss: 0.4797 - accuracy: 0.8659 - val_loss: 16.6072 - val_accuracy: 0.1400\n",
            "Epoch 61/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 0.4791 - accuracy: 0.8651 - val_loss: 16.5114 - val_accuracy: 0.1378\n",
            "Epoch 62/100\n",
            "27644/27644 [==============================] - 4s 136us/step - loss: 0.4782 - accuracy: 0.8654 - val_loss: 16.8657 - val_accuracy: 0.1556\n",
            "Epoch 63/100\n",
            "27644/27644 [==============================] - 4s 143us/step - loss: 0.4756 - accuracy: 0.8656 - val_loss: 16.8564 - val_accuracy: 0.1356\n",
            "Epoch 64/100\n",
            "27644/27644 [==============================] - 4s 133us/step - loss: 0.4761 - accuracy: 0.8662 - val_loss: 17.0730 - val_accuracy: 0.1311\n",
            "Epoch 65/100\n",
            "27644/27644 [==============================] - 4s 149us/step - loss: 0.4725 - accuracy: 0.8670 - val_loss: 16.8019 - val_accuracy: 0.1356\n",
            "Epoch 66/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 0.4732 - accuracy: 0.8660 - val_loss: 16.6808 - val_accuracy: 0.1422\n",
            "Epoch 67/100\n",
            "27644/27644 [==============================] - 4s 151us/step - loss: 0.4722 - accuracy: 0.8655 - val_loss: 17.1689 - val_accuracy: 0.1511\n",
            "Epoch 68/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.4711 - accuracy: 0.8656 - val_loss: 16.7432 - val_accuracy: 0.1467\n",
            "Epoch 69/100\n",
            "27644/27644 [==============================] - 4s 155us/step - loss: 0.4670 - accuracy: 0.8667 - val_loss: 16.8876 - val_accuracy: 0.1533\n",
            "Epoch 70/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.4682 - accuracy: 0.8655 - val_loss: 17.2691 - val_accuracy: 0.1378\n",
            "Epoch 71/100\n",
            "27644/27644 [==============================] - 4s 132us/step - loss: 0.4647 - accuracy: 0.8665 - val_loss: 16.9008 - val_accuracy: 0.1556\n",
            "Epoch 72/100\n",
            "27644/27644 [==============================] - 4s 145us/step - loss: 0.4648 - accuracy: 0.8666 - val_loss: 16.8859 - val_accuracy: 0.1578\n",
            "Epoch 73/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.4635 - accuracy: 0.8670 - val_loss: 17.0636 - val_accuracy: 0.1533\n",
            "Epoch 74/100\n",
            "27644/27644 [==============================] - 4s 143us/step - loss: 0.4619 - accuracy: 0.8666 - val_loss: 17.2626 - val_accuracy: 0.1444\n",
            "Epoch 75/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 0.4619 - accuracy: 0.8662 - val_loss: 17.1069 - val_accuracy: 0.1556\n",
            "Epoch 76/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.4616 - accuracy: 0.8663 - val_loss: 16.9748 - val_accuracy: 0.1556\n",
            "Epoch 77/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 0.4595 - accuracy: 0.8664 - val_loss: 17.2437 - val_accuracy: 0.1578\n",
            "Epoch 78/100\n",
            "27644/27644 [==============================] - 4s 146us/step - loss: 0.4592 - accuracy: 0.8666 - val_loss: 17.0629 - val_accuracy: 0.1378\n",
            "Epoch 79/100\n",
            "27644/27644 [==============================] - 4s 139us/step - loss: 0.4587 - accuracy: 0.8669 - val_loss: 17.3379 - val_accuracy: 0.1489\n",
            "Epoch 80/100\n",
            "27644/27644 [==============================] - 4s 137us/step - loss: 0.4576 - accuracy: 0.8664 - val_loss: 17.4574 - val_accuracy: 0.1556\n",
            "Epoch 81/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.4575 - accuracy: 0.8665 - val_loss: 17.1663 - val_accuracy: 0.1378\n",
            "Epoch 82/100\n",
            "27644/27644 [==============================] - 4s 136us/step - loss: 0.4564 - accuracy: 0.8655 - val_loss: 16.9335 - val_accuracy: 0.1600\n",
            "Epoch 83/100\n",
            "27644/27644 [==============================] - 4s 134us/step - loss: 0.4563 - accuracy: 0.8654 - val_loss: 17.1690 - val_accuracy: 0.1511\n",
            "Epoch 84/100\n",
            "27644/27644 [==============================] - 4s 146us/step - loss: 0.4555 - accuracy: 0.8659 - val_loss: 17.2556 - val_accuracy: 0.1333\n",
            "Epoch 85/100\n",
            "27644/27644 [==============================] - 4s 138us/step - loss: 0.4536 - accuracy: 0.8655 - val_loss: 17.3922 - val_accuracy: 0.1444\n",
            "Epoch 86/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 0.4528 - accuracy: 0.8663 - val_loss: 17.3342 - val_accuracy: 0.1511\n",
            "Epoch 87/100\n",
            "27644/27644 [==============================] - 4s 142us/step - loss: 0.4504 - accuracy: 0.8668 - val_loss: 17.5377 - val_accuracy: 0.1622\n",
            "Epoch 88/100\n",
            "27644/27644 [==============================] - 4s 141us/step - loss: 0.4516 - accuracy: 0.8670 - val_loss: 17.4911 - val_accuracy: 0.1333\n",
            "Epoch 89/100\n",
            "27644/27644 [==============================] - 4s 161us/step - loss: 0.4493 - accuracy: 0.8670 - val_loss: 17.3332 - val_accuracy: 0.1444\n",
            "Epoch 90/100\n",
            "27644/27644 [==============================] - 4s 149us/step - loss: 0.4492 - accuracy: 0.8667 - val_loss: 17.5190 - val_accuracy: 0.1400\n",
            "Epoch 91/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.4504 - accuracy: 0.8658 - val_loss: 17.7595 - val_accuracy: 0.1511\n",
            "Epoch 92/100\n",
            "27644/27644 [==============================] - 4s 137us/step - loss: 0.4475 - accuracy: 0.8664 - val_loss: 17.7101 - val_accuracy: 0.1556\n",
            "Epoch 93/100\n",
            "27644/27644 [==============================] - 4s 137us/step - loss: 0.4477 - accuracy: 0.8668 - val_loss: 17.9555 - val_accuracy: 0.1622\n",
            "Epoch 94/100\n",
            "27644/27644 [==============================] - 4s 149us/step - loss: 0.4475 - accuracy: 0.8664 - val_loss: 17.8515 - val_accuracy: 0.1444\n",
            "Epoch 95/100\n",
            "27644/27644 [==============================] - 4s 145us/step - loss: 0.4458 - accuracy: 0.8660 - val_loss: 17.7911 - val_accuracy: 0.1400\n",
            "Epoch 96/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 0.4463 - accuracy: 0.8666 - val_loss: 18.1521 - val_accuracy: 0.1444\n",
            "Epoch 97/100\n",
            "27644/27644 [==============================] - 4s 136us/step - loss: 0.4459 - accuracy: 0.8660 - val_loss: 17.8814 - val_accuracy: 0.1689\n",
            "Epoch 98/100\n",
            "27644/27644 [==============================] - 4s 144us/step - loss: 0.4457 - accuracy: 0.8671 - val_loss: 18.3250 - val_accuracy: 0.1311\n",
            "Epoch 99/100\n",
            "27644/27644 [==============================] - 4s 135us/step - loss: 0.4430 - accuracy: 0.8672 - val_loss: 18.1923 - val_accuracy: 0.1511\n",
            "Epoch 100/100\n",
            "27644/27644 [==============================] - 4s 147us/step - loss: 0.4426 - accuracy: 0.8682 - val_loss: 18.2986 - val_accuracy: 0.1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi7xebJVHip-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWuGNBtweMpA",
        "colab_type": "text"
      },
      "source": [
        "## Predictions:\n",
        "I have modified and used used the prediction code from this [Reference](https://towardsdatascience.com/exploring-the-next-word-predictor-5e22aeb85d8f) for padding and extracting maximum probable next word from the output vector using argsort()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3vmBvE6WgBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_glove=tf.keras.models.load_model('/content/word_model_8_gram.h5')\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_glove(input):                       \n",
        "  input_text = re.sub(\"\\s+\", \" \", (re.sub(\"[^a-z ]+\", \" \", input)))\n",
        "  encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "\n",
        "  pad_encoded = pad_sequences([encoded_text], maxlen=seqlength, truncating='pre') # code from REFERENCE {\n",
        "  print(encoded_text, pad_encoded)\n",
        "  i = (model_glove.predict(pad_encoded)[0]).argsort()[-1:][::-1][0]\n",
        "  pred_word = tokenizer.index_word[i]\n",
        "  print(\"Next word:\",pred_word)                                                   # }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc6_0WieHCAP",
        "colab_type": "code",
        "outputId": "1b11a148-bbae-411e-b556-67aac6156e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "predict_glove(\"the dead body was in\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 149, 108, 7, 6] [[  0   0   0   1 149 108   7   6]]\n",
            "Next word: spite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ021dawHCeu",
        "colab_type": "code",
        "outputId": "e6d9baae-95be-4ce8-e4ff-e175196b61af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "predict_glove(\" the man and woman began to wonder whether\") # similar to corpus : then he began to wonder when"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 28, 2, 24, 502, 4, 503, 295] [[  1  28   2  24 502   4 503 295]]\n",
            "Next word: i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZwDd-JA-llq",
        "colab_type": "code",
        "outputId": "84bf2d68-1188-4fb1-d713-8b4125b80865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "predict_glove(\"the dead body was in the dark room and there was a\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 149, 108, 7, 6, 1, 91, 2, 45, 7, 5] [[ 7  6  1 91  2 45  7  5]]\n",
            "Next word: nervous\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KStNkXMrJHWC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnHfi3FTIYbC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#**Implementation 2**\n",
        "\n",
        "\n",
        "---\n",
        "Similar to the above implementation but because i am appending the POS_tag feature to the input sentence, it makes the 1D vector into 2D vector, so i will be directly inputing this to an LSTM Layer omitting the Embedding Layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M60R0CHzIVPG",
        "colab_type": "code",
        "outputId": "e0302f58-05f3-40a7-8e0e-06c16fd47874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "import keras\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from keras import models\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryvn6_EJLMl9",
        "colab_type": "text"
      },
      "source": [
        "##Validation Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT_nVMPPIVVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_text= \"\"\"\n",
        "the man pushed the woman away and asked the surgeon whether the man is dead. \n",
        "How can someone do this to him? \n",
        "he was a good man. \n",
        "I wanted him to die, said the woman. \n",
        "the man was agitated. \n",
        "He turned around as there was a hand on his shoulder.\n",
        "A tall man stood motionless. \n",
        "I should not go out at this hour of the day. \n",
        "It was cold outside and I was wet. \n",
        "I looked up to see if the stars were out. \n",
        "I do not know what to say. \n",
        "This information is useless. \n",
        "this produced a good impression on my mother. \n",
        "I will never leave you alone or out of sight. \n",
        "you must be with me.\n",
        "where was that. \n",
        "where is it\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N572SLncLTWV",
        "colab_type": "text"
      },
      "source": [
        "##Data Preprocessing\n",
        "\n",
        "I've written the processes as functions, so that i can call them in the prediction function as it can not use keras paddding features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXowqOb7IVvs",
        "colab_type": "code",
        "outputId": "985096a3-52ff-4bb5-804d-a691c55201cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "path=\"/content/corpus.txt\"\n",
        "with open(path) as f:\n",
        "    text = f.read().lower().replace(\"\\n\",\" \")\n",
        "\n",
        "\n",
        "def preprocess(text, val_text = val_text):   \n",
        "  text = re.split(\"[.?!;]+\", text)        # split the text into sentences\n",
        "  val_text = re.split(\"[.?!;]+\", val_text)\n",
        "  i = 0\n",
        "  dummy = []\n",
        "  for sentence in text:\n",
        "    text[i] = re.sub(\"[^a-z ]+\", \"\", sentence)\n",
        "    k = text[i].split()                     # split sentences into words\n",
        "    if(len(k)>1):                           # omit sentences that have only one word\n",
        "      dummy.append(k)\n",
        "    i += 1\n",
        "  text = dummy\n",
        "  return text, val_text\n",
        "\n",
        "text, val_text = preprocess(text)\n",
        "val_len = len(val_text)\n",
        "text[-17:]                                 # Validation texts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'man',\n",
              "  'pushed',\n",
              "  'the',\n",
              "  'woman',\n",
              "  'away',\n",
              "  'and',\n",
              "  'asked',\n",
              "  'the',\n",
              "  'surgeon',\n",
              "  'whether',\n",
              "  'the',\n",
              "  'man',\n",
              "  'is',\n",
              "  'dead'],\n",
              " ['how', 'can', 'someone', 'do', 'this', 'to', 'him'],\n",
              " ['he', 'was', 'a', 'good', 'man'],\n",
              " ['i', 'wanted', 'him', 'to', 'die', 'said', 'the', 'woman'],\n",
              " ['the', 'man', 'was', 'agitated'],\n",
              " ['he',\n",
              "  'turned',\n",
              "  'around',\n",
              "  'as',\n",
              "  'there',\n",
              "  'was',\n",
              "  'a',\n",
              "  'hand',\n",
              "  'on',\n",
              "  'his',\n",
              "  'shoulder'],\n",
              " ['a', 'tall', 'man', 'stood', 'motionless'],\n",
              " ['i', 'should', 'not', 'go', 'out', 'at', 'this', 'hour', 'of', 'the', 'day'],\n",
              " ['it', 'was', 'cold', 'outside', 'and', 'i', 'was', 'wet'],\n",
              " ['i', 'looked', 'up', 'to', 'see', 'if', 'the', 'stars', 'were', 'out'],\n",
              " ['i', 'do', 'not', 'know', 'what', 'to', 'say'],\n",
              " ['this', 'information', 'is', 'useless'],\n",
              " ['this', 'produced', 'a', 'good', 'impression', 'on', 'my', 'mother'],\n",
              " ['i', 'will', 'never', 'leave', 'you', 'alone', 'or', 'out', 'of', 'sight'],\n",
              " ['you', 'must', 'be', 'with', 'me'],\n",
              " ['where', 'is', 'the'],\n",
              " ['where', 'is', 'it']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqOiFjfqL9Dj",
        "colab_type": "text"
      },
      "source": [
        "##Annotatate text with POS_tag\n",
        "\n",
        "nltk's pos tagger library is used to annotate all the words in the text.\n",
        "\n",
        "I also maintain a dictionary of all the pos_taggers to append them as features in the next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVp1TX40IVrx",
        "colab_type": "code",
        "outputId": "77a3fa83-dd46-45ed-d46f-ea58b68dced8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def text_to_pos(text):\n",
        "  dummy, pos_text=[], []\n",
        "  pos_dict = {}\n",
        "  iter = 1\n",
        "  for i in range(len(text)):\n",
        "    dummy=[]\n",
        "    for word, pos in nltk.pos_tag(text[i]):\n",
        "      if(pos not in pos_dict.keys()):         \n",
        "        pos_dict[pos] = iter                # make a dictionary for POS\n",
        "        iter+=1\n",
        "      dummy.append([word] + [pos])\n",
        "    pos_text.append(dummy)\n",
        "\n",
        "  return pos_text, pos_dict\n",
        "\n",
        "pos_text , pos_dict = text_to_pos(text)\n",
        "print(pos_text[0:2])\n",
        "print(pos_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['one', 'CD'], ['winters', 'NNS'], ['evening', 'VBG'], ['towards', 'IN'], ['the', 'DT'], ['close', 'NN'], ['of', 'IN'], ['the', 'DT'], ['year', 'NN'], ['or', 'CC'], ['within', 'IN'], ['a', 'DT'], ['year', 'NN'], ['or', 'CC'], ['two', 'CD'], ['of', 'IN'], ['that', 'DT'], ['time', 'NN'], ['a', 'DT'], ['young', 'JJ'], ['medical', 'JJ'], ['practitioner', 'NN'], ['recently', 'RB'], ['established', 'VBN'], ['in', 'IN'], ['business', 'NN'], ['was', 'VBD'], ['seated', 'VBN'], ['by', 'IN'], ['a', 'DT'], ['cheerful', 'JJ'], ['fire', 'NN'], ['in', 'IN'], ['his', 'PRP$'], ['little', 'JJ'], ['parlour', 'JJ'], ['listening', 'NN'], ['to', 'TO'], ['the', 'DT'], ['wind', 'NN'], ['which', 'WDT'], ['was', 'VBD'], ['beating', 'VBG'], ['the', 'DT'], ['rain', 'NN'], ['in', 'IN'], ['pattering', 'VBG'], ['drops', 'NNS'], ['against', 'IN'], ['the', 'DT'], ['window', 'NN'], ['or', 'CC'], ['rumbling', 'VBG'], ['dismally', 'RB'], ['in', 'IN'], ['the', 'DT'], ['chimney', 'NN']], [['the', 'DT'], ['night', 'NN'], ['was', 'VBD'], ['wet', 'JJ'], ['and', 'CC'], ['cold', 'JJ']]]\n",
            "{'CD': 1, 'NNS': 2, 'VBG': 3, 'IN': 4, 'DT': 5, 'NN': 6, 'CC': 7, 'JJ': 8, 'RB': 9, 'VBN': 10, 'VBD': 11, 'PRP$': 12, 'TO': 13, 'WDT': 14, 'PRP': 15, 'JJR': 16, 'WRB': 17, 'MD': 18, 'VB': 19, 'JJS': 20, 'RP': 21, 'EX': 22, 'WP': 23, 'VBZ': 24, 'WP$': 25, 'VBP': 26, 'PDT': 27, 'RBR': 28, 'RBS': 29}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzUaCS8OMhfT",
        "colab_type": "text"
      },
      "source": [
        "##Keras Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e08_WqzfIVlf",
        "colab_type": "code",
        "outputId": "46c9d695-63f6-4513-825b-836e1f2f8a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "data = tokenizer.texts_to_sequences(text)\n",
        "vocab_size = len(tokenizer.word_counts) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5Us4_0MmnG",
        "colab_type": "text"
      },
      "source": [
        "##Vectorised [Word, POS_Tag]\n",
        "Now, combining both the Keras tokenised words and the corresponding integer for the POS_tag whic was stored in the dictionary (pos_dict) we otain our dataset which is appended with POS feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzdgyDUeIVjm",
        "colab_type": "code",
        "outputId": "3f5fa9f5-a40d-4560-c557-e8929fc8c658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def text_to_vector(pos_text):\n",
        "  dummy, pos_vector = [], []\n",
        "\n",
        "  for i in range(len(pos_text)):\n",
        "    dummy=[]\n",
        "    for word, pos in pos_text[i]:\n",
        "      dummy.append( tokenizer.texts_to_sequences([word])[0] + [pos_dict[pos]] )\n",
        "    pos_vector.append(dummy)                      # [ Token(word) + Token(POS) ]\n",
        "  return pos_vector\n",
        "pos_vector = text_to_vector(pos_text)\n",
        "print(pos_vector[1:3])\n",
        "print(len(data[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1, 5], [77, 6], [7, 11], [199, 8], [2, 7], [78, 8]], [[8, 15], [15, 11], [34, 10], [467, 3], [54, 4], [200, 6], [2, 7], [119, 6], [1, 5], [278, 8], [120, 6], [2, 7], [7, 11], [49, 9], [279, 9], [468, 3], [6, 4], [9, 12], [469, 6], [2, 7], [470, 2], [92, 16], [64, 4], [201, 8], [471, 8], [2, 7], [280, 16], [64, 4], [201, 8], [472, 8], [473, 3], [5, 5], [474, 6], [475, 2], [6, 4], [9, 12], [476, 6], [281, 6]]]\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwpYw41RJLrx",
        "colab_type": "text"
      },
      "source": [
        "##Train Validation Split\n",
        "\n",
        "The POS_tagged sentences are combined as shown previosly. They are made into 8_gram sequences so each sequence in the dataset is in the shape of (seqlength, 2) which is (8, 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx234PCLIVfQ",
        "colab_type": "code",
        "outputId": "08d14f24-dc72-43cb-e6cd-69f3f90a27e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "seqlength = 8\n",
        "X, y, X_val, y_val = [], [], [], []\n",
        "for i in range(1, seqlength+1):  #1-5 is the different sequence length of the input data\n",
        "  iter=0\n",
        "  for j in range(len(pos_vector)):\n",
        "    for k in range(len(pos_text[iter])-i):\n",
        "      if(j<len(pos_vector)-val_len):\n",
        "        X.append(pos_vector[iter][k : k+i])\n",
        "        X[-1] = [[0, 0]]*(seqlength-i) + X[-1]        #pre-padding\n",
        "        #print(\"i j k data[iter][k:k+i] X\", i,j,k,data[iter][k:k+i], X)\n",
        "        y.append( pos_vector[iter][k+i][1] )\n",
        "      else:\n",
        "        X_val.append(pos_vector[iter][k : k+i])\n",
        "        X_val[-1] = [[0,0]]*(seqlength-i) + X_val[-1] #pre-padding\n",
        "        #print(\"i j k data[iter][k:k+i] X\", i,j,k,data[iter][k:k+i], X)\n",
        "        y_val.append( pos_vector[iter][k+i][1] )\n",
        "    iter += 1\n",
        "\n",
        "X = np.array(X, dtype='int32')\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "X_val = np.array(X_val, dtype='int32')\n",
        "y_val = to_categorical(y_val, num_classes=vocab_size)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27219, 8, 2)\n",
            "(27219, 1345)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wkl6BWdRz4t",
        "colab_type": "text"
      },
      "source": [
        "##Model\n",
        "\n",
        "Iterated over different, \n",
        "- Number of LSTM layers\n",
        "- Number of units and nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BeknUtIVc9",
        "colab_type": "code",
        "outputId": "89c16fe3-ad6b-4d4e-c42f-b583ddeb1c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=X[0].shape, return_sequences=True)) #return_sequences will be True when we have the next layer as LSTM as well.\n",
        "model.add(LSTM(100, return_sequences = False))\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, validation_data=(X_val, y_val), verbose=1, shuffle='True')\n",
        "\n",
        "model.save(\"word_with_pos.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_16 (LSTM)               (None, 8, 100)            41200     \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 300)               30300     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1345)              404845    \n",
            "=================================================================\n",
            "Total params: 556,745\n",
            "Trainable params: 556,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 27219 samples, validate on 450 samples\n",
            "Epoch 1/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 2.6001 - accuracy: 0.2503 - val_loss: 2.4462 - val_accuracy: 0.2556\n",
            "Epoch 2/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 2.3340 - accuracy: 0.2968 - val_loss: 2.4608 - val_accuracy: 0.2267\n",
            "Epoch 3/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 2.2395 - accuracy: 0.3194 - val_loss: 2.3224 - val_accuracy: 0.3000\n",
            "Epoch 4/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 2.1502 - accuracy: 0.3434 - val_loss: 2.2822 - val_accuracy: 0.3111\n",
            "Epoch 5/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 2.0823 - accuracy: 0.3577 - val_loss: 2.2246 - val_accuracy: 0.3444\n",
            "Epoch 6/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 2.0067 - accuracy: 0.3765 - val_loss: 2.2367 - val_accuracy: 0.3311\n",
            "Epoch 7/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.9428 - accuracy: 0.3944 - val_loss: 2.1892 - val_accuracy: 0.3844\n",
            "Epoch 8/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.8692 - accuracy: 0.4100 - val_loss: 2.2931 - val_accuracy: 0.3756\n",
            "Epoch 9/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.7949 - accuracy: 0.4277 - val_loss: 2.3777 - val_accuracy: 0.3378\n",
            "Epoch 10/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.7165 - accuracy: 0.4496 - val_loss: 2.4256 - val_accuracy: 0.3733\n",
            "Epoch 11/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.6352 - accuracy: 0.4700 - val_loss: 2.5437 - val_accuracy: 0.3644\n",
            "Epoch 12/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.5489 - accuracy: 0.4961 - val_loss: 2.5595 - val_accuracy: 0.3444\n",
            "Epoch 13/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.4688 - accuracy: 0.5205 - val_loss: 2.7817 - val_accuracy: 0.3644\n",
            "Epoch 14/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.3917 - accuracy: 0.5498 - val_loss: 2.7317 - val_accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.3184 - accuracy: 0.5741 - val_loss: 2.8293 - val_accuracy: 0.3800\n",
            "Epoch 16/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.2490 - accuracy: 0.5962 - val_loss: 3.0009 - val_accuracy: 0.3356\n",
            "Epoch 17/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.1858 - accuracy: 0.6204 - val_loss: 3.0173 - val_accuracy: 0.3933\n",
            "Epoch 18/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 1.1291 - accuracy: 0.6439 - val_loss: 3.0261 - val_accuracy: 0.3733\n",
            "Epoch 19/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.0727 - accuracy: 0.6594 - val_loss: 3.3107 - val_accuracy: 0.3489\n",
            "Epoch 20/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 1.0248 - accuracy: 0.6775 - val_loss: 3.3471 - val_accuracy: 0.3533\n",
            "Epoch 21/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.9810 - accuracy: 0.6926 - val_loss: 3.4099 - val_accuracy: 0.3578\n",
            "Epoch 22/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.9458 - accuracy: 0.7031 - val_loss: 3.4966 - val_accuracy: 0.3667\n",
            "Epoch 23/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.9113 - accuracy: 0.7149 - val_loss: 3.6229 - val_accuracy: 0.3356\n",
            "Epoch 24/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.8870 - accuracy: 0.7215 - val_loss: 3.6488 - val_accuracy: 0.3511\n",
            "Epoch 25/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.8550 - accuracy: 0.7310 - val_loss: 3.7116 - val_accuracy: 0.3467\n",
            "Epoch 26/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.8319 - accuracy: 0.7389 - val_loss: 3.7345 - val_accuracy: 0.3600\n",
            "Epoch 27/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.8150 - accuracy: 0.7423 - val_loss: 3.7887 - val_accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.8004 - accuracy: 0.7471 - val_loss: 3.9037 - val_accuracy: 0.3511\n",
            "Epoch 29/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7742 - accuracy: 0.7549 - val_loss: 3.9036 - val_accuracy: 0.3844\n",
            "Epoch 30/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7655 - accuracy: 0.7558 - val_loss: 4.0344 - val_accuracy: 0.3556\n",
            "Epoch 31/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7520 - accuracy: 0.7600 - val_loss: 3.9003 - val_accuracy: 0.4044\n",
            "Epoch 32/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7398 - accuracy: 0.7637 - val_loss: 3.9696 - val_accuracy: 0.3822\n",
            "Epoch 33/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7231 - accuracy: 0.7664 - val_loss: 4.1838 - val_accuracy: 0.3489\n",
            "Epoch 34/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.7207 - accuracy: 0.7688 - val_loss: 4.3098 - val_accuracy: 0.3378\n",
            "Epoch 35/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.7078 - accuracy: 0.7723 - val_loss: 4.1533 - val_accuracy: 0.3422\n",
            "Epoch 36/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6987 - accuracy: 0.7746 - val_loss: 4.3160 - val_accuracy: 0.3378\n",
            "Epoch 37/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6898 - accuracy: 0.7775 - val_loss: 4.4422 - val_accuracy: 0.3556\n",
            "Epoch 38/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6770 - accuracy: 0.7824 - val_loss: 4.4031 - val_accuracy: 0.3556\n",
            "Epoch 39/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6813 - accuracy: 0.7771 - val_loss: 4.4622 - val_accuracy: 0.3244\n",
            "Epoch 40/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6646 - accuracy: 0.7836 - val_loss: 4.5636 - val_accuracy: 0.3022\n",
            "Epoch 41/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6624 - accuracy: 0.7835 - val_loss: 4.4352 - val_accuracy: 0.3689\n",
            "Epoch 42/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6530 - accuracy: 0.7871 - val_loss: 4.5730 - val_accuracy: 0.3533\n",
            "Epoch 43/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6494 - accuracy: 0.7881 - val_loss: 4.7262 - val_accuracy: 0.3178\n",
            "Epoch 44/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6425 - accuracy: 0.7904 - val_loss: 4.8099 - val_accuracy: 0.3511\n",
            "Epoch 45/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6405 - accuracy: 0.7901 - val_loss: 4.6291 - val_accuracy: 0.3689\n",
            "Epoch 46/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6316 - accuracy: 0.7931 - val_loss: 5.0815 - val_accuracy: 0.3422\n",
            "Epoch 47/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6284 - accuracy: 0.7936 - val_loss: 4.6564 - val_accuracy: 0.3822\n",
            "Epoch 48/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6219 - accuracy: 0.7944 - val_loss: 4.7504 - val_accuracy: 0.3311\n",
            "Epoch 49/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.6162 - accuracy: 0.7960 - val_loss: 4.8664 - val_accuracy: 0.3644\n",
            "Epoch 50/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.6151 - accuracy: 0.7955 - val_loss: 4.8582 - val_accuracy: 0.3556\n",
            "Epoch 51/100\n",
            "27219/27219 [==============================] - 27s 1ms/step - loss: 0.6081 - accuracy: 0.8001 - val_loss: 4.9140 - val_accuracy: 0.3667\n",
            "Epoch 52/100\n",
            "27219/27219 [==============================] - 27s 992us/step - loss: 0.6081 - accuracy: 0.7994 - val_loss: 5.0757 - val_accuracy: 0.3133\n",
            "Epoch 53/100\n",
            "27219/27219 [==============================] - 27s 1ms/step - loss: 0.6048 - accuracy: 0.8011 - val_loss: 5.0908 - val_accuracy: 0.3444\n",
            "Epoch 54/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5986 - accuracy: 0.8015 - val_loss: 5.1277 - val_accuracy: 0.3356\n",
            "Epoch 55/100\n",
            "27219/27219 [==============================] - 27s 1ms/step - loss: 0.5912 - accuracy: 0.8029 - val_loss: 5.2853 - val_accuracy: 0.3178\n",
            "Epoch 56/100\n",
            "27219/27219 [==============================] - 27s 990us/step - loss: 0.5932 - accuracy: 0.8027 - val_loss: 5.2520 - val_accuracy: 0.3467\n",
            "Epoch 57/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5961 - accuracy: 0.8027 - val_loss: 5.3094 - val_accuracy: 0.3289\n",
            "Epoch 58/100\n",
            "27219/27219 [==============================] - 27s 991us/step - loss: 0.5814 - accuracy: 0.8051 - val_loss: 5.3237 - val_accuracy: 0.3000\n",
            "Epoch 59/100\n",
            "27219/27219 [==============================] - 27s 995us/step - loss: 0.5883 - accuracy: 0.8039 - val_loss: 5.2147 - val_accuracy: 0.3511\n",
            "Epoch 60/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5785 - accuracy: 0.8088 - val_loss: 5.3434 - val_accuracy: 0.3356\n",
            "Epoch 61/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5746 - accuracy: 0.8092 - val_loss: 5.3943 - val_accuracy: 0.3178\n",
            "Epoch 62/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5746 - accuracy: 0.8101 - val_loss: 5.6012 - val_accuracy: 0.3311\n",
            "Epoch 63/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5719 - accuracy: 0.8087 - val_loss: 5.2153 - val_accuracy: 0.3711\n",
            "Epoch 64/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5728 - accuracy: 0.8088 - val_loss: 5.6018 - val_accuracy: 0.3156\n",
            "Epoch 65/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5677 - accuracy: 0.8111 - val_loss: 5.4106 - val_accuracy: 0.3244\n",
            "Epoch 66/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5680 - accuracy: 0.8106 - val_loss: 5.7057 - val_accuracy: 0.3222\n",
            "Epoch 67/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5612 - accuracy: 0.8125 - val_loss: 5.6085 - val_accuracy: 0.3556\n",
            "Epoch 68/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5595 - accuracy: 0.8142 - val_loss: 5.8769 - val_accuracy: 0.3244\n",
            "Epoch 69/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5601 - accuracy: 0.8119 - val_loss: 5.6003 - val_accuracy: 0.3200\n",
            "Epoch 70/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5552 - accuracy: 0.8145 - val_loss: 5.6061 - val_accuracy: 0.3133\n",
            "Epoch 71/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5550 - accuracy: 0.8142 - val_loss: 5.8215 - val_accuracy: 0.2978\n",
            "Epoch 72/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5511 - accuracy: 0.8147 - val_loss: 5.7012 - val_accuracy: 0.3511\n",
            "Epoch 73/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5492 - accuracy: 0.8150 - val_loss: 5.5449 - val_accuracy: 0.3333\n",
            "Epoch 74/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5484 - accuracy: 0.8139 - val_loss: 5.8907 - val_accuracy: 0.3267\n",
            "Epoch 75/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5474 - accuracy: 0.8172 - val_loss: 5.8249 - val_accuracy: 0.3378\n",
            "Epoch 76/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5452 - accuracy: 0.8164 - val_loss: 5.7818 - val_accuracy: 0.3400\n",
            "Epoch 77/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5423 - accuracy: 0.8178 - val_loss: 5.9525 - val_accuracy: 0.3422\n",
            "Epoch 78/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5405 - accuracy: 0.8182 - val_loss: 5.7228 - val_accuracy: 0.3467\n",
            "Epoch 79/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5364 - accuracy: 0.8190 - val_loss: 5.8914 - val_accuracy: 0.3600\n",
            "Epoch 80/100\n",
            "27219/27219 [==============================] - 30s 1ms/step - loss: 0.5386 - accuracy: 0.8178 - val_loss: 6.1958 - val_accuracy: 0.3222\n",
            "Epoch 81/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5297 - accuracy: 0.8212 - val_loss: 6.0669 - val_accuracy: 0.3378\n",
            "Epoch 82/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5288 - accuracy: 0.8223 - val_loss: 5.8945 - val_accuracy: 0.3444\n",
            "Epoch 83/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5318 - accuracy: 0.8197 - val_loss: 5.8182 - val_accuracy: 0.3733\n",
            "Epoch 84/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5311 - accuracy: 0.8202 - val_loss: 6.0605 - val_accuracy: 0.3222\n",
            "Epoch 85/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5301 - accuracy: 0.8198 - val_loss: 5.9281 - val_accuracy: 0.3400\n",
            "Epoch 86/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5251 - accuracy: 0.8225 - val_loss: 5.9518 - val_accuracy: 0.3356\n",
            "Epoch 87/100\n",
            "27219/27219 [==============================] - 27s 1ms/step - loss: 0.5262 - accuracy: 0.8229 - val_loss: 6.0127 - val_accuracy: 0.3489\n",
            "Epoch 88/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5204 - accuracy: 0.8246 - val_loss: 6.2515 - val_accuracy: 0.3111\n",
            "Epoch 89/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5253 - accuracy: 0.8224 - val_loss: 6.0164 - val_accuracy: 0.3511\n",
            "Epoch 90/100\n",
            "27219/27219 [==============================] - 27s 989us/step - loss: 0.5195 - accuracy: 0.8238 - val_loss: 6.1736 - val_accuracy: 0.3378\n",
            "Epoch 91/100\n",
            "27219/27219 [==============================] - 27s 995us/step - loss: 0.5238 - accuracy: 0.8204 - val_loss: 6.3067 - val_accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "27219/27219 [==============================] - 27s 996us/step - loss: 0.5235 - accuracy: 0.8216 - val_loss: 6.1879 - val_accuracy: 0.3311\n",
            "Epoch 93/100\n",
            "27219/27219 [==============================] - 27s 995us/step - loss: 0.5184 - accuracy: 0.8237 - val_loss: 6.4340 - val_accuracy: 0.3311\n",
            "Epoch 94/100\n",
            "27219/27219 [==============================] - 27s 979us/step - loss: 0.5166 - accuracy: 0.8253 - val_loss: 6.3103 - val_accuracy: 0.3244\n",
            "Epoch 95/100\n",
            "27219/27219 [==============================] - 29s 1ms/step - loss: 0.5136 - accuracy: 0.8247 - val_loss: 6.2308 - val_accuracy: 0.3356\n",
            "Epoch 96/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5129 - accuracy: 0.8244 - val_loss: 6.2529 - val_accuracy: 0.3422\n",
            "Epoch 97/100\n",
            "27219/27219 [==============================] - 27s 1ms/step - loss: 0.5142 - accuracy: 0.8245 - val_loss: 6.3212 - val_accuracy: 0.3511\n",
            "Epoch 98/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5138 - accuracy: 0.8244 - val_loss: 6.4667 - val_accuracy: 0.3467\n",
            "Epoch 99/100\n",
            "27219/27219 [==============================] - 28s 1ms/step - loss: 0.5095 - accuracy: 0.8268 - val_loss: 6.5214 - val_accuracy: 0.3089\n",
            "Epoch 100/100\n",
            "27219/27219 [==============================] - 27s 1000us/step - loss: 0.5054 - accuracy: 0.8284 - val_loss: 6.3283 - val_accuracy: 0.3511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QITNW734wBjv",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Used the padding and preprocessing functions i wrote and used argsort() from the [Reference](https://towardsdatascience.com/exploring-the-next-word-predictor-5e22aeb85d8f) as mentioned earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXpc6qsjJsm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "model_pos = tf.keras.models.load_model(\"/content/word_with_pos.h5\")\n",
        "\n",
        "def predict_with_pos(input):\n",
        "  input_text = input.strip().lower()\n",
        "  input_text, _ = preprocess(input_text)\n",
        "  test_pos_text, _ = text_to_pos(input_text)\n",
        "  encoded_text = text_to_vector(test_pos_text)[0]\n",
        "  print(encoded_text)\n",
        "  \n",
        "  pad_encoded = encoded_text  #for retaining shape\n",
        "  l_encoded = len(encoded_text)\n",
        "  \n",
        "  if(seqlength>=l_encoded):\n",
        "    pad_encoded = [[[0, 0]]*(seqlength-l_encoded) + encoded_text]\n",
        "  else:\n",
        "    pad_ecoded[i] = [encoded_text[-seqlength:]]\n",
        "  pad_encoded = array(pad_encoded)\n",
        "  print(pad_encoded)\n",
        "\n",
        "  i = (model_pos.predict(pad_encoded)[0]).argsort()[-1:][::-1][0]  #from REFERENCE\n",
        "  pred_word = tokenizer.index_word[i]                          #from REFERENCE\n",
        "  print(\"Next word :\",pred_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR1i_I_ZSUtQ",
        "colab_type": "code",
        "outputId": "3d77df19-db8d-4c22-d420-01920b9794ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "predict_with_pos(\"he thought the wind\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8, 15], [121, 11], [1, 5], [275, 6]]\n",
            "[[[  0   0]\n",
            "  [  0   0]\n",
            "  [  0   0]\n",
            "  [  0   0]\n",
            "  [  8  15]\n",
            "  [121  11]\n",
            "  [  1   5]\n",
            "  [275   6]]]\n",
            "Next word : was\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRtMGizHSVBJ",
        "colab_type": "code",
        "outputId": "61634b8d-1b1c-424b-8bed-03c6a44dee09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "predict_with_pos(\"if he could only tell her\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[36, 4], [8, 15], [80, 18], [127, 9], [203, 19], [19, 12]]\n",
            "[[[  0   0]\n",
            "  [  0   0]\n",
            "  [ 36   4]\n",
            "  [  8  15]\n",
            "  [ 80  18]\n",
            "  [127   9]\n",
            "  [203  19]\n",
            "  [ 19  12]]]\n",
            "Next word : to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfMRRBBjSVTr",
        "colab_type": "code",
        "outputId": "843d1132-5f1c-435e-ab81-45cb9e9ffb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "predict_with_pos(\"not a moment is to be\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18, 9], [5, 5], [122, 6], [32, 24], [4, 13], [22, 19]]\n",
            "[[[  0   0]\n",
            "  [  0   0]\n",
            "  [ 18   9]\n",
            "  [  5   5]\n",
            "  [122   6]\n",
            "  [ 32  24]\n",
            "  [  4  13]\n",
            "  [ 22  19]]]\n",
            "Next word : it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0EuVjnLFHIs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Inference\n",
        "\n",
        "- The **1st Implementation** which uses a pretrained glove embedding works better and fits better on the corpus.\n",
        "\n",
        "- **2nd Implementation** mostly Outputs the words that are used frequently in the corpus like [the, of, a, in ,be, that...], I am still learning on how to add features to the Input. Although Validation accuracy is higher for this implementation\n",
        "\n",
        "- **Validation accuracy** is not a good metric for evaluating our model as the output is categorical and it punishes even similar words that have been predicted as output. \n",
        "\n",
        "- An Interesting **[Research paper](https://arxiv.org/pdf/1602.06291.pdf)** that helped me understand the addition of Features in the text is CLSTM ( Contextual LSTM ), where the input text is added with a 'Topic' that is calculated seperately. This Topic feature is not added directly to the input text, rather to the embedding layer.\n",
        "\n",
        "So i still have to explore how to **add regualrized features to the embedding layer.** There is an [Open Source Code](https://github.com/kafkasl/contextualLSTM) by Pol Alvarez trying to replicate this paper.\n",
        "\n",
        "[All References](https://github.com/svtsanoj/Word-Predictor/blob/master/references.txt)\n",
        "\n",
        "--Sanoj"
      ]
    }
  ]
}